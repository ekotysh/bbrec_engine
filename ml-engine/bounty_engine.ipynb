{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rWAjdfIsTyhI"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWAjdfIsTyhI"
      },
      "source": [
        "## ML 207 Final Project ##\n",
        "### Bug Bounty Price Recommendation Engine ###\n",
        "### Github repo: https://github.com/ekotysh/bbrec_engine ###\n",
        "\n",
        "**by Eduard Kotysh**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0KwRzrQTyhL"
      },
      "source": [
        "# Intro\n",
        "---\n",
        "In this project, I want to create an ML algorithm that guesses the bug bounty price range for a given vulnerability. \n",
        "\n",
        "**Problem:** Currently, there is a big challenge in the field of Security Disclosure in determining how much a bug bounty should cost or how much a researcher should get paid for their responsible disclosure. \n",
        "\n",
        "Each company tends to select its own price ranges for bug bounties based on the multitude of factors, such as: \n",
        " - how much they can afford to pay (this often boils down to company size, revenue, etc.)\n",
        " - location of the company (major tech cities tend to pay more)\n",
        " - the type of vulnerability and the affected scope\n",
        " - the severity of vulnerability\n",
        " - how much they believe a bug should be worth (highly subjective)\n",
        " - others\n",
        "\n",
        "**Goal:** Our goal for this project is to capture some of these factors in the dataset and create an ML algorithm that is able to accurately discern the price range of a given vulnerability based on some of these factors.\n",
        "\n",
        "At the very minimum, the user should be able to supply the **Type of Vulnerability, and its Severity**, and the ML engine would guess the price range of how much it's worth. \n",
        "\n",
        "**Usability:** I forsee this will be used by companies as a recommendation engine API to determine how much they should pay for bug bounties and existing vulnerabilities that have occurred. This could be offered as a free service at first to gather data and improve the ML engine. Once the accuracy is sufficient, it could become a paid service.\n",
        "\n",
        "## Data Gathering\n",
        "We want to gather existing data on paid vulnerabilities. Ideally, we want to gather as much information about the vulnerability as possible (this would comprise our training/test dataset) and an actual price that was paid (this would be our target label). \n",
        "\n",
        "This is a fairly difficult dataset to obtain, since the information is quite sensitive and unless both, the company and the dev agreed to disclose the bounty report, this information is typically unavailable.\n",
        "\n",
        "**To my knowledge, there are no public datasets available that include bug bounty reports and their corresponding paid rewards.**\n",
        "\n",
        "To collect this data, I decided to write a custom crawler for HackerOne that scouts the site for disclosed bug reports (only a fraction of them is mutually disclosed) and intelligently extracts specific fields of each report using jQuery. jQuery is handy for finding DOM elements and extracting data from them. I used Apify webscraper api and built my own crawler code on top of it that you can find [here](https://raw.githubusercontent.com/ekotysh/bbrec_engine/main/crawler/apify_code.js).\n",
        "\n",
        "\n",
        "Using this technique, **I was able to obtain 2415 records** after 4 hours of runtime. \n",
        "\n",
        "\n",
        "## Data Preparation & Analysis\n",
        "###  1. Removing critical missing data ###\n",
        "The initial data I crawled contained a lot of missing information. While some missing information is OK (such as report date or severity score) other information is absolutely essential (bounty price, company name, severity <i>rating</i>, weakness type, etc).\n",
        "\n",
        "I wrote a python script (`prune-empty-rewards.py`) to search for rows with critical missing data and remove them from the dataset. After this step, **I ended up with 1342 rows of clean data.**\n",
        "\n",
        "\n",
        "### 2. Dealing with non-critical missing data ###\n",
        "The other fields that were sometimes missing were non-critical meaning that the ML algorithm should still be able to make a fairly accurate decision. Perhaps, it wouldn't be as accurate as if it were with this data present, but it wouldn't skew the training or become an outlier. \n",
        "\n",
        "For these fields, the key to success was selecting a consistent \"No value\" placeholder that ML algo can learn as a signle separate categorical option. I had to be careful not to introduce multiple categorical options that meant the same thing, because that would certainly confuse the algorithm.\n",
        "\n",
        "To accomplish this, I wrote a script (`fix-nans.py`) to find instances where fields were missing in different forms (such as '---' or '-' or empty) and replace them with a single consistent 'No value' placeholder.\n",
        "\n",
        "\n",
        "### 3. Enriching the Data ###\n",
        "I wanted to supplement my data with additional information for accuracy.\n",
        "\n",
        "From my prior experience with estimating bug bounties, I knew that **company's size and location were often considerable factors** that played into the bug bounty price. \n",
        "\n",
        "To add this information, I wrote a script (`enrich-data.py`) that used APIs: \n",
        "  - Crunchbase API (to get basic company data)\n",
        "  - Companies API (to get revenue and location data)\n",
        "  - Google Maps API (to lash the location to city/state/country consistently)\n",
        "\n",
        "This allowed me to have a much richer dataset that consisted of:\n",
        "  - Company Name\n",
        "  - Company Size\n",
        "  - Company Revenue\n",
        "  - Company Location (City, State, Country)\n",
        "  - Bounty Awarded ($$$)\n",
        "  - Bounty Weakness (i.e. SQL Injection)\n",
        "  - Bounty Report Title (Text)\n",
        "  - Bounty Report Description (Text)\n",
        "  - Severity Rating (Low, Medium, High, Critical)\n",
        "  - Severity Score (0-10)\n",
        "  - Report Date\n",
        "  - URL\n",
        "\n",
        "### 4. Analyzing the Data ###\n",
        "**Open-Source data:** \n",
        "\n",
        "While looking at the data and the corresponding bounty payouts, I realized that there was a significant discreptency between Open Source Projects/Communities and For-Profit Organizations. The Open-Source projects often provided lower payouts for the same types/severity of vulnerability. \n",
        "\n",
        "I decided to manually label those projects as \"Open Source\", thus introducing a new binary column into my dataset. This way, my ML algorithm would take this into account and hopefully be more accurate in its decision making.\n",
        "\n",
        "**Dates:** \n",
        "\n",
        "Another caviat is the representation of dates in ML dataset. After reading [this article](https://towardsdatascience.com/machine-learning-with-datetime-feature-engineering-predicting-healthcare-appointment-no-shows-5e4ca3a85f96), I decided to explode each date into separate categorical columns: Year, Month, Day, Min - that would help ML algo create better associations/decisions in the process. I wrote a script that went through my entire dataset and converted the date into these categorical columns: `explode-dates.py` script.\n",
        "\n",
        "**Binarization:** \n",
        "\n",
        "Since we're dealing with a lot of categorical data, as long as the number of variations for each feature is not overwhelming, it is best to binarize each variation, so that decision trees have a way at analyzing which variations were important. I accomplished it using `pd.get_dummies` and passing it the specific columns I wanted to binarize, leaving out the `Description` column, which had to be handled differently, as otherwise, all of its values would be unique.\n",
        "\n",
        "\n",
        "### 5. Machine Learning Methods & Error Analysis ###\n",
        "**Price Ranges:** \n",
        "\n",
        "After running some preliminary results using just default Decision Trees, I noticed that I was getting very poor results (~13% accuracy). I went back to analyzing my data and wrote a script `analyze-bounties.py` to see how many unique bounty prices I have. I ended up with 235 different bounty prices (target labels) across a 1342-row dataset. The variety of target labels here is quite vast across a rather small dataset, so no wonder the accuracy is poor. \n",
        "\n",
        "Instead, I decided to split my bounty prices into ranges:\n",
        "  - `$0-1000`\n",
        "  - `$1000-2000`\n",
        "  - `$2000-5000`\n",
        "  - `$5000-10000`\n",
        "  - `$10000 plus`\n",
        "\n",
        "This way instead of 135 target labels, we only have 5, while still making it a usable MVP product for users.\n",
        "\n",
        "This significantly improved the accuracy of decision trees to over 50%. \n",
        "\n",
        "**Vectorizing the Description (Tfidf vs Count):** \n",
        "\n",
        "I tried using both, <b>tf-idf</b> and <b>count</b> vectorizers on description to see how they perform. While they both transform text into numeric form useful for machine learning models, the CountVectorizer simply produces the frequency of each token with respect to the index in the vocabulary. However, the **TfidfVectorizer hints at the overall originality** of the word by counting how many times it appears in the document vs the number of documents that token appears in.\n",
        "\n",
        "I visualized the decision tree diagrams at multiple maxdepths for both vectorizers and found that in the case of using plain CountVectorizer, the tree tends to overfit right away, as I see some leafs containing company-specific terms from description like \"dropbox\" for example. Using tfidf produced much more original results and slightly better accuracy (by ~0.05).\n",
        "\n",
        "**Decision Tree Tuning:**\n",
        "\n",
        "At first attempt, I used the `DecisionTreeClassifier` without any params and it performed quite poorly (0.58 accuracy). It was clearly overfitting, because the training set accuracy was 1. To fix this, I decided to go the pre-prunning route and restrict the maximum depth of the tree to 3 or 4. \n",
        "To see what was happening with the tree exactly, I found a `graphviz` library I could use to save the tree to a .dot file and plot it visually.\n",
        "\n",
        "- **With depth=3**, our trainset accuracy dropped to 0.695, but our test accuracy improved significantly from 0.58 -> to 0.6965, which told to me that it is overfitting much less over train data than it was before. \n",
        "Inspecting the tree tests visually, the decision chain made sense:\n",
        "1. First, it started with checking whether severity is over 9.5 (since this immediately drops us into a much larger category of bounties).\n",
        "2. If severity score was less than 9.5, the next test it chose was to see if the severity <i>rating</i> was higher than Low. This also makes sense, as it's now testing the lower bound to see just how low the bug severity is.\n",
        "3. If severity score was 9.5 or higher, then the follow-up tests included checking the Description for important clues as to what type of vulnerability it is. For example, in one of the tests, it's checking for `__priveleg` hinting at the fact that when Privilige escalation has occured, it warrants the highest payout label.\n",
        "(Refer to the diagram for the full tree visualization).\n",
        "\n",
        "- **With depth=4**, I then decided to try depth=4, which would make the tree more complex, possibly give us a higher score, but may overfit more. The trainset accuracy improved to 0.71, while the test accuracy dropped from 0.695 (at depth=3) -> to 0.683. This immediately hints at overfitting from depth=3, since the test score went down, while train score went up. \n",
        "I decided to look at the visual tree just to see what it came up with, and as expected, we see that at level 4 the tree starts making decisions off terms like \"dropbox\" and \"summary\", which are not really important in the overall decision making about bug bounty price or severity. \n",
        "<br></br>\n",
        "\n",
        "**Bringing it Together Using Pipeline**:\n",
        "\n",
        "I wanted to join the results of my vectorized description with the results of Decision Tree classifier on other fields. This way, the Decision Tree takes into account all binarized features, together with tfdif'd description features. \n",
        "\n",
        "I was able to find a `make_pipeline` function that allowed me put it all together like this:\n",
        "```\n",
        "tree = DecisionTreeClassifier(max_depth=maxdepth, random_state=42)\n",
        "ct1 = make_column_transformer((cv_desc, 'Report Description'), remainder='passthrough')\n",
        "pipeline = make_pipeline(ct1, tree)\n",
        "pipeline.fit(train_X, train_Y)\n",
        "```\n",
        "\n",
        "\n",
        "This performs column vectorization transformation over Description, while allowing other columns to 'passthrough' to the DecisionTreeClassifier without change. Then, decision tree takes them all together and analyzes.\n",
        "<br></br>\n",
        "### 6. Future Improvements ###\n",
        "\n",
        "- Get more data (5000-10000 records)\n",
        "- Look into joining `Weakness` and `Title` into the Pipline, along with Description\n",
        "- More detailed tuning with Random Forest classifier\n",
        "- Try post-pruning techniques instead of pre-pruning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNNjknnZTyhN"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# General libraries.\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix, classification report\n",
        "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Decision trees and Random Forest\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Decision tree diagrams.\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "# Pipelining vectorized column into other data\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Feature extraction from text\n",
        "from sklearn.feature_extraction.text import *\n",
        "\n",
        "# Stop words and stemming\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Pretty print\n",
        "from pprint import pprint\n",
        "from tabulate import tabulate\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orEWeRJaTyhO"
      },
      "source": [
        "Load the data, stripping out metadata so that only textual features will be used, and restricting documents to 4 specific topics. By default, newsgroups data is split into training and test sets, but here the test set gets further split into development and test sets.  (If you remove the categories argument from the fetch function calls, you'd get documents from all 20 topics.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_file = 'https://raw.githubusercontent.com/ekotysh/bbrec_engine/main/dataset/final_bb_dataset_with_ranges.csv'\n",
        "\n",
        "\n",
        "header_names = ['Company Name', 'Company Size', 'Open Source', 'Company Revenue',\n",
        "              'Bounty Awarded', 'Severity Rating', 'Severity Score', 'Weakness',\n",
        "              'Report Title', 'Report Description', 'URL', \n",
        "              'Company State', 'Company Country', 'Company City',\n",
        "              'Report Year', 'Report Month', 'Report Day', 'Report Hour', 'Report Minute',\n",
        "              'Bounty Ranges']\n",
        "\n",
        "# Read the csv in from my github repo\n",
        "df = pd.read_csv(dataset_file, names=header_names)\n",
        "\n",
        "# Remove the dollar sign from bounties\n",
        "# df[\"Bounty Awarded\"] = df[\"Bounty Awarded\"].replace({'\\$':''}, regex = True)\n",
        "\n",
        "# Get the target labels (our bug bounty prices)\n",
        "labels = df.loc[:,\"Bounty Ranges\"]\n"
      ],
      "metadata": {
        "id": "j_4PXwDCcXr_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(s):\n",
        "  # combine english, russian and custom non-words\n",
        "  non_words = {'hi', 'hello', 'pleas', 'like', 'bug', 'bounty', 'bounti', 'nov', 'oct', \n",
        "               'ago', 'think', 'thank', 'need', 'howev', 'year hi', 'year hello', 'thank report'}\n",
        "  stop_words = set(stopwords.words('english')).union(set(stopwords.words('russian'))).union(non_words)\n",
        "  clean_words = []  # keep track of only clean words (non-stop)\n",
        "  tokenized_str = word_tokenize(s)\n",
        "  # go through each token and add it to clean if it's not a stop word\n",
        "  for word in tokenized_str:\n",
        "    if word not in stop_words:\n",
        "      clean_words.append(word)\n",
        "\n",
        "  # convert from list back to string\n",
        "  clean_str = ' '.join(clean_words)\n",
        "  return clean_str \n",
        "\n",
        "def remove_numbers(s):\n",
        "  # go through any sequence of numbers and replace them with nnn using regex\n",
        "  pattern = '[0-9]+'\n",
        "  repl = 'nnn'\n",
        "  return re.sub(pattern, repl, s)\n",
        "\n",
        "def remove_apostophes(s):\n",
        "  # replace the occurences of two different types of apostrophes (' & ’) with an empty space\n",
        "  pattern1 = \"(?<=[a-z])'(?=[a-z])\"\n",
        "  repl = ' '\n",
        "  pattern2 = \"(?<=[a-z])’(?=[a-z])\"\n",
        "  s1 = re.sub(pattern1, repl, s)\n",
        "  return re.sub(pattern2, repl, s1)\n",
        "\n",
        "def add_stems(s):\n",
        "  # for each word, return a stem instead\n",
        "  ps = PorterStemmer()\n",
        "  stems = \"\"\n",
        "  tokenized_str = word_tokenize(s)  # tokenize the string\n",
        "  for word in tokenized_str:\n",
        "    stems = stems + \" \" + ps.stem(word)\n",
        "\n",
        "  # only return stems\n",
        "  return stems\n",
        "\n",
        "# preprocessor for vectorizing text fields\n",
        "def text_preprocessor(s):\n",
        "  s = remove_numbers(s)\n",
        "  s = remove_apostophes(s) \n",
        "  s = remove_stop_words(s)\n",
        "  s = add_stems(s) \n",
        "  s = s.lower()\n",
        "  return s"
      ],
      "metadata": {
        "id": "3azhvV_78hgU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BugReport:\n",
        "\n",
        "  no_value = \"No value\"\n",
        "  company_size = no_value\n",
        "  open_source = 0.0\n",
        "  severity_rating = no_value\n",
        "  severity_score = no_value\n",
        "  weakness = no_value\n",
        "  description = no_value\n",
        "  company_state = no_value \n",
        "  company_country = no_value\n",
        "  company_city = no_value\n",
        "  report_year = no_value\n",
        "  report_month = no_value\n",
        "  report_day = no_value\n",
        "\n",
        "  def __init__(self, company_size=no_value, open_source=0.0, severity_rating=no_value, severity_score=no_value,\n",
        "               weakness=no_value, description=no_value, company_state=no_value, company_country=no_value, company_city=no_value,\n",
        "               report_year=no_value, report_month=no_value, report_day=no_value):\n",
        "    \n",
        "    self.company_size = company_size\n",
        "    self.open_source = open_source\n",
        "    self.severity_rating = severity_rating\n",
        "    self.severity_score = severity_score\n",
        "    self.weakness = weakness\n",
        "    self.description = description\n",
        "    self.company_state = company_state\n",
        "    self.company_country = company_country\n",
        "    self.company_city = company_city\n",
        "    self.report_year = report_year\n",
        "    self.report_month = report_month\n",
        "    self.report_day = report_day\n",
        "\n",
        "  def tolist(self):\n",
        "    return [self.company_size, self.open_source, self.severity_rating, self.severity_score,\n",
        "            self.weakness, self.description, self.company_state, self.company_country,\n",
        "            self.company_city, self.report_year, self.report_month, self.report_day]\n",
        "\n",
        "\n",
        "def vectorize_column(name, column, min_df_val, ngram_start, ngram_end):\n",
        "  print(f\"Vectorizing Description column using Tfidf ngram=({ngram_start}, {ngram_end})...\")\n",
        "  # tokenize by word + remove words that appear in fewer than min_df_val documents.\n",
        "  #cv = CountVectorizer(min_df=min_df_val, preprocessor=text_preprocessor)\n",
        "  cv = TfidfVectorizer(min_df=min_df_val, ngram_range=(ngram_start, ngram_end),\n",
        "                       preprocessor=text_preprocessor)\n",
        "\n",
        "  vectorized = cv.fit_transform(column)\n",
        "  feature_names = cv.get_feature_names_out()\n",
        "\n",
        "  print(f\"\\tTfidf'd {name} vocabulary: {feature_names}\")\n",
        "  print(\"\\tSize of vocabulary:\", feature_names.shape[0])\n",
        "  print(\"\\tFraction of Non-zero entries:\", vectorized.nnz / (vectorized.shape[0]*vectorized.shape[1]))\n",
        "  print(\"\")\n",
        "  return cv\n",
        "\n",
        "def run_random_forest(ct1, train_X, test_X, train_Y, test_Y):\n",
        "\n",
        "  # Random Forest Pipeline:\n",
        "  print(\"Building a Random Forest Pipeline...\")\n",
        "  pipeline = make_pipeline(ct1, RandomForestClassifier())\n",
        "\n",
        "  pipeline.fit(train_X, train_Y)\n",
        "  score_train = pipeline.score(train_X, train_Y)\n",
        "  score_test  = pipeline.score(test_X, test_Y)\n",
        "\n",
        "  print(\"\\tOverall Accuracy (train):\", score_train) \n",
        "  print(\"\\tOverall Accuracy (test):\", score_test)\n",
        "  print(\"\")\n",
        "\n",
        "def run_decision_tree(maxdepth, ct1, train_X, test_X, train_Y, test_Y):\n",
        "\n",
        "  # Decision Tree Pipeline:\n",
        "  print(f\"Building a Decision Tree Pipeline with MaxDepth={maxdepth}...\")\n",
        "  tree = DecisionTreeClassifier(max_depth=maxdepth, random_state=42)\n",
        "  pipeline = make_pipeline(ct1, tree)\n",
        "  pipeline.fit(train_X, train_Y)\n",
        "  score_train = pipeline.score(train_X, train_Y)\n",
        "  score_test  = pipeline.score(test_X, test_Y)\n",
        "  \n",
        "  #pred_y = tree.predict(test_X)\n",
        "  #results = confusion_matrix(test_Y, pred_y)\n",
        "  #error = zero_one_loss(test_Y, pred_y)\n",
        "\n",
        "  print(\"\\tOverall Accuracy (train):\", score_train)\n",
        "  print(\"\\tOverall Accuracy (test):\", score_test)\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"\\tExporting tree diagram...\")\n",
        "  export_graphviz(tree, out_file=\"tree.dot\", \n",
        "                  class_names=['0-1000', '1000-2000', '2000-5000', '5000-10000', '10000-plus'],\n",
        "                  feature_names=ct1.get_feature_names_out(),\n",
        "                  impurity=False, filled=True)\n",
        "  \n",
        "  with open(\"tree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "  \n",
        "  display(graphviz.Source(dot_graph))\n",
        "  print(\"\")\n",
        "\n",
        "\n",
        "def predict_custom_bugreports(desc_transformer, train_X, train_Y, bugreports_df):\n",
        "  print(\"Predicting Custom Bug Reports...\")\n",
        "  print(\"\")\n",
        "\n",
        "  pipeline = make_pipeline(desc_transformer, RandomForestClassifier())\n",
        "\n",
        "  pipeline.fit(train_X, train_Y)\n",
        "\n",
        "  preds = pipeline.predict(bugreports_df)\n",
        "\n",
        "  custom_reports = []\n",
        "  idx = 0\n",
        "  for index, row in bugreports_df.iterrows():\n",
        "    report = \"\"\n",
        "    for col in bugreports_df.columns:\n",
        "      if row[col] != 0 and re.search('Severity Rating|Weakness|Company Size|Company State', col):\n",
        "        report += f\"{col}: {row[col]}\\n\"\n",
        "    \n",
        "    custom_reports.append([report, \"$\" + preds[idx]])\n",
        "    idx += 1\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Predictions:\")\n",
        "  data = []\n",
        "  print(tabulate(custom_reports, headers=[\"Bug Report:\", \"Predicted Bug Bounty $$$:\"], tablefmt='fancy_grid'))\n",
        "\n",
        "\n",
        "def main():\n",
        "  # Note: 'Company Revenue' actually hurts accuracy\n",
        "  #'Weakness', 'Report Title', 'Report Description',\n",
        "  train_columns = ['Company Size', 'Open Source', \n",
        "                'Severity Rating', 'Severity Score', 'Weakness', \n",
        "                'Report Description', \n",
        "                'Company State', 'Company Country', 'Company City',\n",
        "                'Report Year', 'Report Month', 'Report Day']\n",
        "\n",
        "  # Pick the columns we're gonna train/test with\n",
        "  clean_df = df[train_columns]\n",
        "  \n",
        "  # convert categorical columns into binary features\n",
        "  binarized_df = pd.get_dummies(clean_df, columns=binarize_columns, drop_first=True)\n",
        "\n",
        "  # Split our dataset in half - 50% train / 50% test\n",
        "  mid_point = int(binarized_df.shape[0] / 2) + 1\n",
        "\n",
        "  # Get our train and test datasets with respective labels\n",
        "  train_df = binarized_df[1:mid_point]\n",
        "  test_df  = binarized_df[mid_point:binarized_df.shape[0]-4]\n",
        "\n",
        "  train_labels = labels[1:mid_point]\n",
        "  test_labels = labels[mid_point:labels.shape[0]-4]\n",
        "\n",
        "  # The last two rows are custom bug reports we want to try and predict\n",
        "  custom_bugreports_df = binarized_df[binarized_df.shape[0]-4:binarized_df.shape[0]]\n",
        "  \n",
        "  # Show all training columns\n",
        "  # pprint(train_df.columns.tolist())\n",
        "\n",
        "  # Vectorize textual fields\n",
        "  # tokenize by word + remove words that appear in fewer than 20 documents.\n",
        "  #cv_titl = vectorize_column(\"Title\",       clean_df['Report Title'], 5)\n",
        "  #ct_titl = make_column_transformer((cv_titl, 'Report Title'), remainder='passthrough')\n",
        "  cv_desc = vectorize_column(\"Description\", clean_df['Report Description'], 2, 1, 1)\n",
        "  ct_desc = make_column_transformer((cv_desc, 'Report Description'), remainder='passthrough')\n",
        "  \n",
        "  # Run a Decision Tree (max-depth=3) in a pipeline with Tfidf'd description \n",
        "  run_decision_tree(3, ct_desc, train_df, test_df, train_labels, test_labels)\n",
        "\n",
        "  # Run a Decision Tree (max-depth=4) in a pipeline with Tfidf'd description \n",
        "  run_decision_tree(4, ct_desc, train_df, test_df, train_labels, test_labels)\n",
        "\n",
        "  # Run a Random Forest classifier in a pipeline with Tfidf'd description \n",
        "  run_random_forest(ct_desc, train_df, test_df, train_labels, test_labels)\n",
        "\n",
        "  # Try Predicting several custom bug reports \n",
        "  predict_custom_bugreports(ct_desc, train_df, train_labels, custom_bugreports_df);\n",
        "\n",
        "\n",
        "# download stopwords and punkt for nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "print()\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "binarize_columns = ['Company Size', 'Open Source',  \n",
        "                    'Severity Rating', 'Severity Score', 'Weakness', \n",
        "                    'Company State', 'Company Country', 'Company City',\n",
        "                    'Report Year', 'Report Month', 'Report Day']\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "8oggsAb0sV8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce92260d-c5db-4fee-b43c-77edbc448da2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vectorizing Description column using Tfidf ngram=(1, 1)...\n",
            "\tTfidf'd Description vocabulary: ['______________nnn' '__cfduid' '__interceptor_malloc' ... 'ценим' 'что'\n",
            " 'это']\n",
            "\tSize of vocabulary: 6305\n",
            "\tFraction of Non-zero entries: 0.014288985951098778\n",
            "\n",
            "Building a Decision Tree Pipeline with MaxDepth=3...\n",
            "\tOverall Accuracy (train): 0.6953937592867756\n",
            "\tOverall Accuracy (test): 0.6965620328849028\n",
            "\n",
            "\tExporting tree diagram...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f82cc7588b0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1397pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 1397.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 1393,-369 1393,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#efb286\" stroke=\"#000000\" points=\"819,-365 553,-365 553,-297 819,-297 819,-365\"/>\n<text text-anchor=\"middle\" x=\"686\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Severity Score_9.5 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"686\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 673</text>\n<text text-anchor=\"middle\" x=\"686\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [452, 106, 15, 67, 33]</text>\n<text text-anchor=\"middle\" x=\"686\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#eeae7f\" stroke=\"#000000\" points=\"689,-261 413,-261 413,-193 689,-193 689,-261\"/>\n<text text-anchor=\"middle\" x=\"551\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Severity Rating_Low &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 638</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [447, 99, 11, 56, 25]</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M641.796,-296.9465C629.5584,-287.519 616.1564,-277.1946 603.4962,-267.4415\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"605.3612,-264.4601 595.3034,-261.13 601.0893,-270.0055 605.3612,-264.4601\"/>\n<text text-anchor=\"middle\" x=\"598.5191\" y=\"-282.2223\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e9e9fc\" stroke=\"#000000\" points=\"974.5,-261 759.5,-261 759.5,-193 974.5,-193 974.5,-261\"/>\n<text text-anchor=\"middle\" x=\"867\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__patch &lt;= 0.006</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 7, 4, 11, 8]</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M745.2662,-296.9465C762.2986,-287.1599 781.0134,-276.4066 798.5517,-266.3294\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.6738,-269.1468 807.6007,-261.13 797.1863,-263.0773 800.6738,-269.1468\"/>\n<text text-anchor=\"middle\" x=\"801.0801\" y=\"-281.5647\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#f0b68d\" stroke=\"#000000\" points=\"420.5,-157 163.5,-157 163.5,-89 420.5,-89 420.5,-157\"/>\n<text text-anchor=\"middle\" x=\"292\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Open Source_1.0 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 525</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [342, 93, 11, 55, 24]</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M466.1937,-192.9465C440.7033,-182.711 412.5796,-171.4181 386.5028,-160.9471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"387.5809,-157.6084 376.9968,-157.13 384.9724,-164.1043 387.5809,-157.6084\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e78a48\" stroke=\"#000000\" points=\"660,-157 442,-157 442,-89 660,-89 660,-157\"/>\n<text text-anchor=\"middle\" x=\"551\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__includ &lt;= 0.079</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 113</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [105, 6, 0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M551,-192.9465C551,-184.776 551,-175.9318 551,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"554.5001,-167.13 551,-157.13 547.5001,-167.13 554.5001,-167.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#eeac7d\" stroke=\"#000000\" points=\"188,-53 0,-53 0,0 188,0 188,-53\"/>\n<text text-anchor=\"middle\" x=\"94\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 425</text>\n<text text-anchor=\"middle\" x=\"94\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [299, 60, 7, 43, 16]</text>\n<text text-anchor=\"middle\" x=\"94\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M222.1926,-88.9777C201.2409,-78.7664 178.3735,-67.6214 157.8288,-57.6085\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.0907,-54.33 148.568,-53.095 156.0239,-60.6224 159.0907,-54.33\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#fbece1\" stroke=\"#000000\" points=\"377.5,-53 206.5,-53 206.5,0 377.5,0 377.5,-53\"/>\n<text text-anchor=\"middle\" x=\"292\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [43, 33, 4, 12, 8]</text>\n<text text-anchor=\"middle\" x=\"292\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M292,-88.9777C292,-80.7364 292,-71.887 292,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.5001,-63.2484 292,-53.2485 288.5001,-63.2485 295.5001,-63.2484\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#e68844\" stroke=\"#000000\" points=\"558.5,-53 395.5,-53 395.5,0 558.5,0 558.5,-53\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 111</text>\n<text text-anchor=\"middle\" x=\"477\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [105, 4, 0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"477\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M524.9104,-88.9777C518.0289,-80.0039 510.5944,-70.3089 503.6822,-61.295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"506.3744,-59.0541 497.5118,-53.2485 500.8196,-63.3137 506.3744,-59.0541\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#7be539\" stroke=\"#000000\" points=\"723,-53 577,-53 577,0 723,0 723,-53\"/>\n<text text-anchor=\"middle\" x=\"650\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"650\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"650\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M585.9037,-88.9777C595.3918,-79.7292 605.6657,-69.7147 615.1509,-60.4691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"617.8407,-62.7349 622.5586,-53.2485 612.9546,-57.7223 617.8407,-62.7349\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#ececfd\" stroke=\"#000000\" points=\"972.5,-157 761.5,-157 761.5,-89 972.5,-89 972.5,-157\"/>\n<text text-anchor=\"middle\" x=\"867\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__caus &lt;= 0.011</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 29</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2, 4, 10, 8]</text>\n<text text-anchor=\"middle\" x=\"867\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M867,-192.9465C867,-184.776 867,-175.9318 867,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"870.5001,-167.13 867,-157.13 863.5001,-167.13 870.5001,-167.13\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#95ea61\" stroke=\"#000000\" points=\"1264.5,-157 1039.5,-157 1039.5,-89 1264.5,-89 1264.5,-157\"/>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__privileg &lt;= 0.007</text>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5, 0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M960.3197,-192.9465C988.615,-182.6212 1019.859,-171.2199 1048.765,-160.6717\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1050.2764,-163.846 1058.4707,-157.13 1047.8768,-157.2701 1050.2764,-163.846\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#e9e9fc\" stroke=\"#000000\" points=\"896.5,-53 741.5,-53 741.5,0 896.5,0 896.5,-53\"/>\n<text text-anchor=\"middle\" x=\"819\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26</text>\n<text text-anchor=\"middle\" x=\"819\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2, 1, 10, 8]</text>\n<text text-anchor=\"middle\" x=\"819\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M850.077,-88.9777C845.7955,-80.3702 841.184,-71.0992 836.858,-62.402\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"839.8923,-60.6433 832.3049,-53.2485 833.6248,-63.7608 839.8923,-60.6433\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#39e5c5\" stroke=\"#000000\" points=\"1061,-53 915,-53 915,0 1061,0 1061,-53\"/>\n<text text-anchor=\"middle\" x=\"988\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"988\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 3, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"988\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 2000&#45;5000</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M909.6601,-88.9777C921.6011,-79.4545 934.5605,-69.1191 946.437,-59.6473\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"948.8246,-62.22 954.4605,-53.2485 944.46,-56.7473 948.8246,-62.22\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#7be539\" stroke=\"#000000\" points=\"1225,-53 1079,-53 1079,0 1225,0 1225,-53\"/>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"1152\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1152,-88.9777C1152,-80.7364 1152,-71.887 1152,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1155.5001,-63.2484 1152,-53.2485 1148.5001,-63.2485 1155.5001,-63.2484\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#3c39e5\" stroke=\"#000000\" points=\"1389,-53 1243,-53 1243,0 1389,0 1389,-53\"/>\n<text text-anchor=\"middle\" x=\"1316\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1316\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"1316\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1209.8203,-88.9777C1226.7052,-79.0424 1245.0922,-68.2232 1261.7478,-58.4228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1263.9585,-61.183 1270.8022,-53.095 1260.4086,-55.1499 1263.9585,-61.183\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building a Decision Tree Pipeline with MaxDepth=4...\n",
            "\tOverall Accuracy (train): 0.7102526002971769\n",
            "\tOverall Accuracy (test): 0.6831091180866966\n",
            "\n",
            "\tExporting tree diagram...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f82c9b89340>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1849pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 1848.50 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-473 1844.5,-473 1844.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#efb286\" stroke=\"#000000\" points=\"1206.5,-469 940.5,-469 940.5,-401 1206.5,-401 1206.5,-469\"/>\n<text text-anchor=\"middle\" x=\"1073.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Severity Score_9.5 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"1073.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 673</text>\n<text text-anchor=\"middle\" x=\"1073.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [452, 106, 15, 67, 33]</text>\n<text text-anchor=\"middle\" x=\"1073.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#eeae7f\" stroke=\"#000000\" points=\"1020.5,-365 744.5,-365 744.5,-297 1020.5,-297 1020.5,-365\"/>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Severity Rating_Low &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 638</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [447, 99, 11, 56, 25]</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1010.9595,-400.9465C992.7386,-391.0252 972.6933,-380.1105 953.9666,-369.9138\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"955.6373,-366.8383 945.1811,-365.13 952.2898,-372.986 955.6373,-366.8383\"/>\n<text text-anchor=\"middle\" x=\"952.2528\" y=\"-385.4089\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#e9e9fc\" stroke=\"#000000\" points=\"1413,-365 1198,-365 1198,-297 1413,-297 1413,-365\"/>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__patch &lt;= 0.006</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 7, 4, 11, 8]</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 0&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>0&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1149.4655,-400.9465C1172.0983,-390.8008 1197.0487,-379.6161 1220.2337,-369.2228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1221.6705,-372.4144 1229.3639,-365.13 1218.807,-366.0268 1221.6705,-372.4144\"/>\n<text text-anchor=\"middle\" x=\"1220.464\" y=\"-384.7922\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#f0b68d\" stroke=\"#000000\" points=\"689,-261 432,-261 432,-193 689,-193 689,-261\"/>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">remainder__Open Source_1.0 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 525</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [342, 93, 11, 55, 24]</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M777.0652,-296.9465C744.5959,-286.4596 708.6901,-274.8626 675.6056,-264.177\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"676.4883,-260.7841 665.8965,-261.0411 674.3368,-267.4453 676.4883,-260.7841\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#e78a48\" stroke=\"#000000\" points=\"999,-261 766,-261 766,-193 999,-193 999,-261\"/>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__dropbox &lt;= 0.209</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 113</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [105, 6, 0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"882.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M882.5,-296.9465C882.5,-288.776 882.5,-279.9318 882.5,-271.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"886.0001,-271.13 882.5,-261.13 879.0001,-271.13 886.0001,-271.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#eeac7d\" stroke=\"#000000\" points=\"400,-157 165,-157 165,-89 400,-89 400,-157\"/>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__summari &lt;= 0.001</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 425</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [299, 60, 7, 43, 16]</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M469.4724,-192.9465C441.872,-182.6212 411.3954,-171.2199 383.1994,-160.6717\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"384.3245,-157.3558 373.7321,-157.13 381.8718,-163.912 384.3245,-157.3558\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#fbece1\" stroke=\"#000000\" points=\"673.5,-157 447.5,-157 447.5,-89 673.5,-89 673.5,-157\"/>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__commit &lt;= 0.011</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [43, 33, 4, 12, 8]</text>\n<text text-anchor=\"middle\" x=\"560.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M560.5,-192.9465C560.5,-184.776 560.5,-175.9318 560.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.0001,-167.13 560.5,-157.13 557.0001,-167.13 564.0001,-167.13\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#eb9d64\" stroke=\"#000000\" points=\"179,-53 0,-53 0,0 179,0 179,-53\"/>\n<text text-anchor=\"middle\" x=\"89.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 288</text>\n<text text-anchor=\"middle\" x=\"89.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [231, 28, 2, 20, 7]</text>\n<text text-anchor=\"middle\" x=\"89.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M214.4554,-88.9777C194.0328,-78.7664 171.7429,-67.6214 151.717,-57.6085\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.1996,-54.4367 142.6901,-53.095 150.0691,-60.6977 153.1996,-54.4367\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#f6d4bb\" stroke=\"#000000\" points=\"368,-53 197,-53 197,0 368,0 368,-53\"/>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 137</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [68, 32, 5, 23, 9]</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M282.5,-88.9777C282.5,-80.7364 282.5,-71.887 282.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"286.0001,-63.2484 282.5,-53.2485 279.0001,-63.2485 286.0001,-63.2484\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#f5fdf1\" stroke=\"#000000\" points=\"557,-53 386,-53 386,0 557,0 557,-53\"/>\n<text text-anchor=\"middle\" x=\"471.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 83</text>\n<text text-anchor=\"middle\" x=\"471.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [28, 32, 4, 11, 8]</text>\n<text text-anchor=\"middle\" x=\"471.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M529.1219,-88.9777C520.6766,-79.8207 511.5389,-69.9129 503.0825,-60.744\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"505.5221,-58.2266 496.1696,-53.2485 500.3764,-62.9723 505.5221,-58.2266\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e89152\" stroke=\"#000000\" points=\"730,-53 575,-53 575,0 730,0 730,-53\"/>\n<text text-anchor=\"middle\" x=\"652.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"652.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15, 1, 0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"652.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M592.9358,-88.9777C601.6657,-79.8207 611.1115,-69.9129 619.8529,-60.744\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"622.6318,-62.9014 626.9989,-53.2485 617.5653,-58.0712 622.6318,-62.9014\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#e68844\" stroke=\"#000000\" points=\"938.5,-157 720.5,-157 720.5,-89 938.5,-89 938.5,-157\"/>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__includ &lt;= 0.079</text>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 111</text>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [105, 4, 0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M865.1458,-192.9465C860.799,-184.4169 856.078,-175.153 851.537,-166.2424\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"854.5522,-164.4505 846.8932,-157.13 848.3154,-167.629 854.5522,-164.4505\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#7be539\" stroke=\"#000000\" points=\"1102.5,-149.5 956.5,-149.5 956.5,-96.5 1102.5,-96.5 1102.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1029.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1029.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"1029.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 9&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M930.6333,-192.9465C947.6037,-180.9403 966.6304,-167.4791 983.4265,-155.5962\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"985.8416,-158.175 991.9837,-149.5422 981.7987,-152.4605 985.8416,-158.175\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#e68640\" stroke=\"#000000\" points=\"911,-53 748,-53 748,0 911,0 911,-53\"/>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 109</text>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [105, 2, 0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"829.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0&#45;1000</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M829.5,-88.9777C829.5,-80.7364 829.5,-71.887 829.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"833.0001,-63.2484 829.5,-53.2485 826.0001,-63.2485 833.0001,-63.2484\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#7be539\" stroke=\"#000000\" points=\"1075.5,-53 929.5,-53 929.5,0 1075.5,0 1075.5,-53\"/>\n<text text-anchor=\"middle\" x=\"1002.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"1002.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"1002.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M890.4933,-88.9777C908.4697,-78.9504 928.0602,-68.0228 945.7581,-58.1508\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"947.7936,-61.0231 954.8219,-53.095 944.3836,-54.9099 947.7936,-61.0231\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#ececfd\" stroke=\"#000000\" points=\"1411,-261 1200,-261 1200,-193 1411,-193 1411,-261\"/>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__caus &lt;= 0.011</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 29</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2, 4, 10, 8]</text>\n<text text-anchor=\"middle\" x=\"1305.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1305.5,-296.9465C1305.5,-288.776 1305.5,-279.9318 1305.5,-271.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1309.0001,-271.13 1305.5,-261.13 1302.0001,-271.13 1309.0001,-271.13\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#95ea61\" stroke=\"#000000\" points=\"1706.5,-261 1500.5,-261 1500.5,-193 1706.5,-193 1706.5,-261\"/>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__shel &lt;= 0.018</text>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5, 0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 14&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>14&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1403.0763,-296.9465C1432.8676,-286.5496 1465.7849,-275.0616 1496.1847,-264.4523\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1497.6708,-267.6408 1505.9591,-261.0411 1495.3643,-261.0317 1497.6708,-267.6408\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#e9e9fc\" stroke=\"#000000\" points=\"1348,-157 1121,-157 1121,-89 1348,-89 1348,-157\"/>\n<text text-anchor=\"middle\" x=\"1234.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tfidfvectorizer__forward &lt;= 0.007</text>\n<text text-anchor=\"middle\" x=\"1234.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26</text>\n<text text-anchor=\"middle\" x=\"1234.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2, 1, 10, 8]</text>\n<text text-anchor=\"middle\" x=\"1234.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1282.2519,-192.9465C1276.245,-184.1475 1269.7045,-174.5672 1263.4457,-165.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1266.3293,-163.4155 1257.8003,-157.13 1260.548,-167.3623 1266.3293,-163.4155\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"#39e5c5\" stroke=\"#000000\" points=\"1512.5,-149.5 1366.5,-149.5 1366.5,-96.5 1512.5,-96.5 1512.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1439.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"1439.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 3, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"1439.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 2000&#45;5000</text>\n</g>\n<!-- 15&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1349.3766,-192.9465C1364.7043,-181.0504 1381.8723,-167.726 1397.0791,-155.9237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1399.5475,-158.4384 1405.3014,-149.5422 1395.2556,-152.9085 1399.5475,-158.4384\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#c6c5f7\" stroke=\"#000000\" points=\"1281,-53 1126,-53 1126,0 1281,0 1281,-53\"/>\n<text text-anchor=\"middle\" x=\"1203.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 22</text>\n<text text-anchor=\"middle\" x=\"1203.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 2, 1, 10, 4]</text>\n<text text-anchor=\"middle\" x=\"1203.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1223.5706,-88.9777C1220.8643,-80.5533 1217.9538,-71.4934 1215.2119,-62.9579\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1218.4836,-61.6988 1212.0928,-53.2485 1211.8191,-63.8398 1218.4836,-61.6988\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#e539c0\" stroke=\"#000000\" points=\"1445.5,-53 1299.5,-53 1299.5,0 1445.5,0 1445.5,-53\"/>\n<text text-anchor=\"middle\" x=\"1372.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"1372.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 0, 0, 4]</text>\n<text text-anchor=\"middle\" x=\"1372.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 10000&#45;plus</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1283.1536,-88.9777C1297.0343,-79.2713 1312.1214,-68.7213 1325.8777,-59.1018\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1328.0589,-61.8475 1334.2483,-53.2485 1324.0474,-56.1109 1328.0589,-61.8475\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#7be539\" stroke=\"#000000\" points=\"1676.5,-149.5 1530.5,-149.5 1530.5,-96.5 1676.5,-96.5 1676.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"1603.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1000&#45;2000</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1603.5,-192.9465C1603.5,-182.2621 1603.5,-170.4254 1603.5,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1607.0001,-159.5421 1603.5,-149.5422 1600.0001,-159.5422 1607.0001,-159.5421\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#3c39e5\" stroke=\"#000000\" points=\"1840.5,-149.5 1694.5,-149.5 1694.5,-96.5 1840.5,-96.5 1840.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1767.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"1767.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"1767.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5000&#45;10000</text>\n</g>\n<!-- 20&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>20&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1657.1997,-192.9465C1676.4801,-180.72 1698.1396,-166.9847 1717.1272,-154.9437\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1719.0744,-157.8534 1725.645,-149.5422 1715.3255,-151.9418 1719.0744,-157.8534\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building a Random Forest Pipeline...\n",
            "\tOverall Accuracy (train): 1.0\n",
            "\tOverall Accuracy (test): 0.6980568011958147\n",
            "\n",
            "Predicting Custom Bug Reports...\n",
            "\n",
            "\n",
            "Predictions:\n",
            "╒═════════════════════════════════════════════╤═════════════════════════════╕\n",
            "│ Bug Report:                                 │ Predicted Bug Bounty $$$:   │\n",
            "╞═════════════════════════════════════════════╪═════════════════════════════╡\n",
            "│ Company Size_1001-5000: 1                   │ $10000-plus                 │\n",
            "│ Severity Rating_High: 1                     │                             │\n",
            "│ Weakness_Business Logic Errors: 1           │                             │\n",
            "│ Company State_California: 1                 │                             │\n",
            "├─────────────────────────────────────────────┼─────────────────────────────┤\n",
            "│ Company Size_1001-5000: 1                   │ $0-1000                     │\n",
            "│ Severity Rating_Low: 1                      │                             │\n",
            "│ Weakness_Business Logic Errors: 1           │                             │\n",
            "│ Company State_California: 1                 │                             │\n",
            "├─────────────────────────────────────────────┼─────────────────────────────┤\n",
            "│ Company Size_1001-5000: 1                   │ $0-1000                     │\n",
            "│ Severity Rating_High: 1                     │                             │\n",
            "│ Weakness_Improper Certificate Validation: 1 │                             │\n",
            "│ Company State_California: 1                 │                             │\n",
            "├─────────────────────────────────────────────┼─────────────────────────────┤\n",
            "│ Company Size_1001-5000: 1                   │ $0-1000                     │\n",
            "│ Severity Rating_Low: 1                      │                             │\n",
            "│ Weakness_Improper Certificate Validation: 1 │                             │\n",
            "│ Company State_California: 1                 │                             │\n",
            "╘═════════════════════════════════════════════╧═════════════════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ----------"
      ],
      "metadata": {
        "id": "oG4U4tcM88va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------"
      ],
      "metadata": {
        "id": "qsn7CtbI89Gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------"
      ],
      "metadata": {
        "id": "wwaBGXqU89P4"
      }
    }
  ]
}